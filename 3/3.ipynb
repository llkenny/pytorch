{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = datasets.fetch_california_housing()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создать Dataset для загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HousingDataset(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, data, target):\n",
    "        self._data = data\n",
    "        self._target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[idx], self._target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = HousingDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обернуть его в Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_ds,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "# при num_workers > 0 выдаёт ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, batch in enumerate(train_loader):\n",
    "#    print(i, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_len = len(df['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(features_len, 64),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(64, 32),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLP()\n",
    "\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   301] loss: 0.961\n",
      "[1,   601] loss: 0.984\n",
      "[1,   901] loss: 0.930\n",
      "[1,  1201] loss: 0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:00<00:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1501] loss: 0.921\n",
      "[2,   301] loss: 0.884\n",
      "[2,   601] loss: 0.851\n",
      "[2,   901] loss: 0.838\n",
      "[2,  1201] loss: 0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:01<00:07,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  1501] loss: 0.808\n",
      "[3,   301] loss: 0.812\n",
      "[3,   601] loss: 0.898\n",
      "[3,   901] loss: 0.797\n",
      "[3,  1201] loss: 0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:02<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  1501] loss: 0.798\n",
      "[4,   301] loss: 0.726\n",
      "[4,   601] loss: 0.743\n",
      "[4,   901] loss: 0.739\n",
      "[4,  1201] loss: 0.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:03<00:05,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  1501] loss: 0.693\n",
      "[5,   301] loss: 0.722\n",
      "[5,   601] loss: 0.846\n",
      "[5,   901] loss: 0.726\n",
      "[5,  1201] loss: 0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:05<00:05,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  1501] loss: 0.661\n",
      "[6,   301] loss: 0.677\n",
      "[6,   601] loss: 0.699\n",
      "[6,   901] loss: 0.668\n",
      "[6,  1201] loss: 0.676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:06<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  1501] loss: 0.709\n",
      "[7,   301] loss: 0.675\n",
      "[7,   601] loss: 0.675\n",
      "[7,   901] loss: 0.729\n",
      "[7,  1201] loss: 0.685\n",
      "[7,  1501] loss: 0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:07<00:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   301] loss: 0.640\n",
      "[8,   601] loss: 0.646\n",
      "[8,   901] loss: 0.683\n",
      "[8,  1201] loss: 0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:08<00:02,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  1501] loss: 0.660\n",
      "[9,   301] loss: 0.655\n",
      "[9,   601] loss: 0.653\n",
      "[9,   901] loss: 0.642\n",
      "[9,  1201] loss: 0.682\n",
      "[9,  1501] loss: 0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:09<00:01,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   301] loss: 0.665\n",
      "[10,   601] loss: 0.681\n",
      "[10,   901] loss: 0.653\n",
      "[10,  1201] loss: 0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,  1501] loss: 0.634\n",
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(10)):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        inputs, targets = data[0].float(), data[1].float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.activation==\"relu\":\n",
    "            return F.relu(x)\n",
    "        if self.activation==\"sigmoid\":\n",
    "            return F.sigmoid(x)\n",
    "        raise RuntimeError\n",
    "        \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        #self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.fc1 = Perceptron(input_dim, hidden_dim)\n",
    "        #self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        #self.dp = nn.Dropout(0.25)\n",
    "        self.fc2 = Perceptron(hidden_dim, 1, \"relu\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.bn2(x)\n",
    "        #x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FeedForward(features_len, 1)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "# criterion = nn.CrossEntropyLoss() # для классификации\n",
    "criterion = nn.L1Loss() # для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   301] loss: 2.043\n",
      "[1,   601] loss: 2.098\n",
      "[1,   901] loss: 2.053\n",
      "[1,  1201] loss: 2.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:00<00:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1501] loss: 2.074\n",
      "[2,   301] loss: 2.076\n",
      "[2,   601] loss: 2.055\n",
      "[2,   901] loss: 2.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:01<00:05,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  1201] loss: 2.073\n",
      "[2,  1501] loss: 2.084\n",
      "[3,   301] loss: 2.089\n",
      "[3,   601] loss: 2.063\n",
      "[3,   901] loss: 2.047\n",
      "[3,  1201] loss: 2.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:02<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  1501] loss: 2.061\n",
      "[4,   301] loss: 2.046\n",
      "[4,   601] loss: 2.066\n",
      "[4,   901] loss: 2.070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:02<00:03,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  1201] loss: 2.066\n",
      "[4,  1501] loss: 2.087\n",
      "[5,   301] loss: 2.067\n",
      "[5,   601] loss: 2.085\n",
      "[5,   901] loss: 2.075\n",
      "[5,  1201] loss: 2.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:03<00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  1501] loss: 2.043\n",
      "[6,   301] loss: 2.051\n",
      "[6,   601] loss: 2.045\n",
      "[6,   901] loss: 2.056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:04<00:02,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  1201] loss: 2.121\n",
      "[6,  1501] loss: 2.073\n",
      "[7,   301] loss: 2.076\n",
      "[7,   601] loss: 2.091\n",
      "[7,   901] loss: 2.040\n",
      "[7,  1201] loss: 2.067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:04<00:01,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,  1501] loss: 2.066\n",
      "[8,   301] loss: 2.053\n",
      "[8,   601] loss: 2.060\n",
      "[8,   901] loss: 2.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:05<00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  1201] loss: 2.094\n",
      "[8,  1501] loss: 2.067\n",
      "[9,   301] loss: 2.054\n",
      "[9,   601] loss: 2.067\n",
      "[9,   901] loss: 2.062\n",
      "[9,  1201] loss: 2.085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:05<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  1501] loss: 2.064\n",
      "[10,   301] loss: 2.056\n",
      "[10,   601] loss: 2.048\n",
      "[10,   901] loss: 2.071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,  1201] loss: 2.085\n",
      "[10,  1501] loss: 2.076\n",
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(10)):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        inputs, targets = data[0].float(), data[1].float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        if self.activation==\"relu\":\n",
    "            return F.relu(x)\n",
    "        if self.activation==\"sigmoid\":\n",
    "            return F.sigmoid(x)\n",
    "        raise RuntimeError\n",
    "        \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(input_dim)\n",
    "        self.fc1 = Perceptron(input_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dp = nn.Dropout(0.25)\n",
    "        self.fc2 = Perceptron(hidden_dim, 1, \"relu\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dp(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FeedForward(features_len, 1)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "# criterion = nn.CrossEntropyLoss() # для классификации\n",
    "criterion = nn.L1Loss() # для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   301] loss: 1.129\n",
      "[1,   601] loss: 0.883\n",
      "[1,   901] loss: 0.836\n",
      "[1,  1201] loss: 0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [00:01<00:14,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1501] loss: 0.676\n",
      "[2,   301] loss: 0.644\n",
      "[2,   601] loss: 0.671\n",
      "[2,   901] loss: 0.659\n",
      "[2,  1201] loss: 0.653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [00:03<00:12,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  1501] loss: 0.678\n",
      "[3,   301] loss: 0.652\n",
      "[3,   601] loss: 0.653\n",
      "[3,   901] loss: 0.669\n",
      "[3,  1201] loss: 0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [00:04<00:10,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  1501] loss: 0.651\n",
      "[4,   301] loss: 0.656\n",
      "[4,   601] loss: 0.662\n",
      "[4,   901] loss: 0.666\n",
      "[4,  1201] loss: 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [00:06<00:09,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  1501] loss: 0.687\n",
      "[5,   301] loss: 0.653\n",
      "[5,   601] loss: 0.653\n",
      "[5,   901] loss: 0.687\n",
      "[5,  1201] loss: 0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [00:07<00:07,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  1501] loss: 0.648\n",
      "[6,   301] loss: 0.668\n",
      "[6,   601] loss: 0.648\n",
      "[6,   901] loss: 0.677\n",
      "[6,  1201] loss: 0.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [00:09<00:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  1501] loss: 0.632\n",
      "[7,   301] loss: 0.654\n",
      "[7,   601] loss: 0.664\n",
      "[7,   901] loss: 0.664\n",
      "[7,  1201] loss: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [00:10<00:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,  1501] loss: 0.659\n",
      "[8,   301] loss: 0.663\n",
      "[8,   601] loss: 0.657\n",
      "[8,   901] loss: 0.667\n",
      "[8,  1201] loss: 0.650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [00:12<00:03,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,  1501] loss: 0.661\n",
      "[9,   301] loss: 0.674\n",
      "[9,   601] loss: 0.656\n",
      "[9,   901] loss: 0.645\n",
      "[9,  1201] loss: 0.669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [00:13<00:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,  1501] loss: 0.671\n",
      "[10,   301] loss: 0.648\n",
      "[10,   601] loss: 0.684\n",
      "[10,   901] loss: 0.637\n",
      "[10,  1201] loss: 0.659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,  1501] loss: 0.660\n",
      "Training is finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(10)):  \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        inputs, targets = data[0].float(), data[1].float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
